{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a402b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import MultiMolGraphDataset, EquiDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from siamesepairwise import SiameseDimeNet\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from schedulers import CosineRestartsDecay\n",
    "import os\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm  # for progress bars\n",
    "from loss_utils import cosine_angle_loss, AngularErrorMetric\n",
    "\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0dc5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4177ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:55:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:55:05] WARNING: not removing hydrogen atom without neighbors\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Built 1696 EquiData examples\n",
      "Saved processed data to data/equi/processed/equi_single_3f0c9001f7b2f62834a490d3aa840439d43bb5f5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Built 1696 EquiData examples\n",
      "Saved processed data to data/equi/processed/equi_single_3f0c9001f7b2f62834a490d3aa840439d43bb5f5.pt\n"
     ]
    }
   ],
   "source": [
    "equi_data = EquiDataset(\n",
    "    root='data/equi',\n",
    "    geoms_csv='/home/calvin/code/GINE/rxn_geometries.csv',\n",
    "    sdf_folder='/home/calvin/code/chemprop_phd_customised/habnet/data/processed/sdf_data' ,\n",
    "    target_csv='/home/calvin/code/chemprop_phd_customised/habnet/data/processed/target_data/target_data_sin_cos.csv',\n",
    "    target_columns=['psi_1_dihedral_sin', 'psi_1_dihedral_cos'],\n",
    "    transform=None,\n",
    "    pre_transform=None,\n",
    "    pre_filter=None,\n",
    "    force_reload=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3db862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([66, 68,  6,  6,  7,  1,  1,  7, 56, 56,  6,  7, 71,  1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equi_data[0].z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b8e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dimenet import DimeNetPPEncoder, FlaggedDimeNetPPEncoder\n",
    "\n",
    "# encoder = FlaggedDimeNetPPEncoder(\n",
    "#     hidden_channels = 256,\n",
    "#     out_channels    = 256,\n",
    "#     num_blocks      = 8,\n",
    "#     dropout         = 0.1,\n",
    "# ).to(device)\n",
    "# encoder = encoder.to(device)\n",
    "encoder = DimeNetPPEncoder(\n",
    "    hidden_channels = 512,\n",
    "    out_channels    = 512,\n",
    "    num_blocks      = 8,\n",
    "    dropout         = 0.1,     # your original DimeNet wrapper handles dropout\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8bf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70b2046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "# Random split using torch\n",
    "train_size = int(0.8 * len(equi_data))\n",
    "valid_size = int(0.1 * len(equi_data))\n",
    "test_size = len(equi_data) - train_size - valid_size\n",
    "# Shuffle the dataset\n",
    "train_data, valid_data, test_data = torch.utils.data.random_split(equi_data, [train_size, valid_size, test_size])\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecf2f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, loss_fn, metric_fn, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_err  = 0.0\n",
    "    n_samples  = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + loss\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            out   = model(batch)              # [B,2]\n",
    "\n",
    "            loss  = loss_fn(out, batch.y)     # scalar\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        # metric: mean abs angle error (degrees)\n",
    "        err = metric_fn(out, batch.y)     # scalar tensor\n",
    "\n",
    "        bsize = batch.y.size(0)\n",
    "        total_loss += loss.item() * bsize\n",
    "        total_err  += err.item()  * bsize\n",
    "        n_samples  += bsize\n",
    "\n",
    "    return total_loss / n_samples, total_err / n_samples\n",
    "\n",
    "def eval_epoch(model, loader, loss_fn, metric_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_err  = 0.0\n",
    "    n_samples  = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validation\", leave=False):\n",
    "            batch = batch.to(device)\n",
    "            out   = model(batch)\n",
    "            loss  = loss_fn(out, batch.y)\n",
    "            err   = metric_fn(out, batch.y)\n",
    "\n",
    "            bsize = batch.y.size(0)\n",
    "            total_loss += loss.item() * bsize\n",
    "            total_err  += err.item()  * bsize\n",
    "            n_samples  += bsize\n",
    "\n",
    "    return total_loss / n_samples, total_err / n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d92b8985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from siamesepairwise import DimeNet\n",
    "\n",
    "model = DimeNet(\n",
    "    encoder=encoder,\n",
    "    dropout=0.2,\n",
    "    head_hidden_dims=[128, 128],\n",
    ")\n",
    "model = model.to(device)\n",
    "num_epochs  = 200\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "# )\n",
    "#scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
    "scheduler = CosineRestartsDecay(\n",
    "    optimizer,\n",
    "    T_0     = 20,\n",
    "    T_mult  = 2,\n",
    "    eta_min = 1e-4,\n",
    "    decay   = 0.3) \n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "loss_fn = cosine_angle_loss\n",
    "metric_fn   = AngularErrorMetric(in_degrees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f45cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train L=0.7533, Err=71.7° | Val   L=0.7974, Err=75.3° | LR=1.00e-04\n",
      " ↳ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train L=0.7261, Err=69.5° | Val   L=0.7952, Err=75.0° | LR=1.00e-04\n",
      " ↳ New best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train L=0.7284, Err=69.8° | Val   L=0.7962, Err=75.1° | LR=1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train L=0.7263, Err=69.5° | Val   L=0.7972, Err=75.2° | LR=1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train L=0.7307, Err=69.8° | Val   L=0.8000, Err=75.7° | LR=1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train L=0.7289, Err=69.7° | Val   L=0.7978, Err=75.3° | LR=1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train L=0.7296, Err=69.7° | Val   L=0.7966, Err=75.1° | LR=1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train L=0.7292, Err=69.6° | Val   L=0.7976, Err=75.3° | LR=1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train L=0.7267, Err=69.5° | Val   L=0.7985, Err=75.4° | LR=1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 55/170 [03:15<07:19,  3.82s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    tr_loss, tr_err = train_epoch(model, train_loader, optimizer, loss_fn, metric_fn, scaler)\n",
    "    va_loss, va_err = eval_epoch(model, valid_loader, loss_fn, metric_fn)\n",
    "\n",
    "    # Step the scheduler once per epoch\n",
    "    # If your scheduler wants the epoch number, do: scheduler.step(epoch)\n",
    "    # Otherwise just:\n",
    "    scheduler.step()\n",
    "\n",
    "    lr = scheduler.get_last_lr()[0]\n",
    "    print(f\"Epoch {epoch:02d} | \"\n",
    "          f\"Train L={tr_loss:.4f}, Err={tr_err:.1f}° | \"\n",
    "          f\"Val   L={va_loss:.4f}, Err={va_err:.1f}° | \"\n",
    "          f\"LR={lr:.2e}\")\n",
    "\n",
    "    # (Optional) save best‐model checkpoint\n",
    "    if va_loss < best_val_loss:\n",
    "        best_val_loss = va_loss\n",
    "        torch.save(model.state_dict(), 'best_dimenet_model.pt')\n",
    "        print(\" ↳ New best model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c12f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# make sure predictions really lie on the circle\n",
    "with torch.no_grad():\n",
    "    out = model(next(iter(train_loader)).to(device))\n",
    "    print(out.norm(dim=1).mean())  # should be ≈1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2f68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0573e-01,  9.7861e-01],\n",
      "        [ 2.9312e-01,  9.5607e-01],\n",
      "        [ 8.4652e-01, -5.3236e-01],\n",
      "        [-3.8566e-02,  9.9926e-01],\n",
      "        [ 8.7958e-01,  4.7576e-01],\n",
      "        [ 9.9661e-02,  9.9502e-01],\n",
      "        [-5.3904e-04,  1.0000e+00],\n",
      "        [-8.3266e-01,  5.5379e-01],\n",
      "        [ 9.6501e-01,  2.6222e-01],\n",
      "        [ 8.8336e-01,  4.6869e-01],\n",
      "        [ 4.8802e-01,  8.7283e-01],\n",
      "        [-5.8331e-04,  1.0000e+00],\n",
      "        [-6.3842e-04,  1.0000e+00],\n",
      "        [ 8.0287e-01,  5.9615e-01],\n",
      "        [-5.3548e-01, -8.4455e-01],\n",
      "        [ 9.8448e-01, -1.7550e-01],\n",
      "        [-9.4104e-01,  3.3829e-01],\n",
      "        [ 3.3494e-01, -9.4224e-01],\n",
      "        [-4.1226e-01,  9.1107e-01],\n",
      "        [ 9.9049e-01,  1.3759e-01],\n",
      "        [-1.9703e-01,  9.8040e-01],\n",
      "        [-6.0893e-01,  7.9322e-01],\n",
      "        [-4.1957e-01,  9.0772e-01],\n",
      "        [-5.3910e-01,  8.4224e-01],\n",
      "        [ 7.4858e-01,  6.6305e-01],\n",
      "        [-8.5713e-01, -5.1510e-01],\n",
      "        [-1.5980e-01,  9.8715e-01],\n",
      "        [ 9.9824e-01, -5.9267e-02],\n",
      "        [-5.9905e-01,  8.0071e-01],\n",
      "        [-4.5903e-01,  8.8842e-01],\n",
      "        [-8.6544e-01,  5.0102e-01],\n",
      "        [-3.3404e-01,  9.4256e-01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    batch = batch.to(device)\n",
    "    print(batch.y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd679ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(\"CUDA memory cleared\")\n",
    "# Print CUDA memory summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmpnn_rocm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
